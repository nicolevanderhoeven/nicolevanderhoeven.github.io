<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>chaos engineering on Nicole van der Hoeven</title>
    <link>https://nicolevanderhoeven.github.io/tags/chaos-engineering/</link>
    <description>Recent content in chaos engineering on Nicole van der Hoeven</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Nicole van der Hoeven</copyright>
    <lastBuildDate>Fri, 26 Feb 2021 21:40:25 +0100</lastBuildDate><atom:link href="https://nicolevanderhoeven.github.io/tags/chaos-engineering/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>k6 Office Hours 03: Chaos Engineering with Daniel González Lopes</title>
      <link>https://nicolevanderhoeven.github.io/blog/20210226-k6-office-hours03/</link>
      <pubDate>Fri, 26 Feb 2021 21:40:25 +0100</pubDate>
      
      <guid>https://nicolevanderhoeven.github.io/blog/20210226-k6-office-hours03/</guid>
      <description>In this week&amp;rsquo;s Office Hours, Simme and I invited Daniel González Lopes, a DevOps engineer from k6, to join us to talk about chaos engineering and what it has to do with load testing. Simme also demonstrated how to use k6 to run simple chaos experiments.
  </description>
    </item>
    
    <item>
      <title>Manufactured Chaos: How Netflix Does Performance Testing</title>
      <link>https://nicolevanderhoeven.github.io/blog/20180328-manufactured-chaos/</link>
      <pubDate>Wed, 28 Mar 2018 23:35:52 +0100</pubDate>
      
      <guid>https://nicolevanderhoeven.github.io/blog/20180328-manufactured-chaos/</guid>
      <description>Originally posted here.
It’s always ideal to run performance tests against an environment that’s production-like. That way, you can ensure that your tests aren&amp;rsquo;t being influenced by factors that are not present in production - such as sub-optimal specifications, or the configurations of a test server. So, what does a good performance tester do? They compare their machine specifications and request production-sized boxes to run their tests against. But is that really enough?</description>
    </item>
    
  </channel>
</rss>
